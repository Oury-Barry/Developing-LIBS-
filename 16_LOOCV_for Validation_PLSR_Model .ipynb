{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad9b037",
   "metadata": {},
   "source": [
    "# ** Leave-One-Out Cross-Validation **\n",
    "<div style=\"margin-top:10px; text-align:justify\";>\n",
    "\n",
    "The Partial Least Squares Regression (PLSR) model was first trained on the dataset. Model validation was then performed using Leave-One-Out Cross-Validation (LOOCV). In this approach, one sample is left out in each iteration, the model is trained on the remaining samples, and tested on the left-out sample. This process is repeated for every sample in the dataset.\n",
    "\n",
    "LOOCV is particularly suitable for small datasets as it provides an unbiased estimate of the modelâ€™s predictive performance on new data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774cca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_concentrations = {\n",
    "    'Al': [..........................], ðŸ‘ˆ#Input element concentrations here\n",
    "    'Cu': [..........................],\n",
    "    'Zn': [..........................],\n",
    "    'Mn': [..........................],\n",
    "    'Fe': [..........................],\n",
    "    'Mg': [..........................],\n",
    "    'Si': [..........................],\n",
    "    'Ni': [..........................]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d2bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_plsr_loocv_full_report(\n",
    "    element,\n",
    "    emission_lines,\n",
    "    peak_max_df,\n",
    "    element_concentrations=None,\n",
    "    assign_sample_colors=None,\n",
    "    cap_width=0.006,\n",
    "    return_model=False,\n",
    "    fixed_n_components=None  # Optional manual override\n",
    "):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.cross_decomposition import PLSRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "    if element_concentrations is None or element not in element_concentrations:\n",
    "        raise ValueError(f\"Missing concentration values for element '{element}'.\")\n",
    "\n",
    "    df = peak_max_df[element]\n",
    "    X = df[emission_lines].values\n",
    "    y = np.array(element_concentrations[element], dtype=float)\n",
    "    sample_labels = df.index.tolist()\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    max_n = min(n_samples - 1, n_features)\n",
    "\n",
    "    metrics_summary = []\n",
    "    details_by_n = {}\n",
    "\n",
    "    print(f\"LOOCV performance for element '{element}' with {max_n} max components:\")\n",
    "\n",
    "    n_range = [fixed_n_components] if fixed_n_components else range(1, max_n + 1)\n",
    "\n",
    "    for n in n_range:\n",
    "        y_true_cv = []\n",
    "        y_pred_cv = []\n",
    "        detailed_records = []\n",
    "\n",
    "        loo = LeaveOneOut()\n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            test_sample = sample_labels[test_idx[0]]\n",
    "            train_samples = [sample_labels[i] for i in train_idx]\n",
    "\n",
    "            model = make_pipeline(StandardScaler(), PLSRegression(n_components=n))\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)[0, 0]\n",
    "            y_true = y_test[0]\n",
    "\n",
    "            y_true_cv.append(y_true)\n",
    "            y_pred_cv.append(y_pred)\n",
    "\n",
    "            abs_error = abs(y_true - y_pred)\n",
    "            rel_error = abs_error / y_true * 100 if y_true != 0 else np.nan\n",
    "\n",
    "            detailed_records.append({\n",
    "                \"Left-Out Sample\": test_sample,\n",
    "                \"Training Samples\": train_samples,\n",
    "                \"True\": round(y_true, 4),\n",
    "                \"Predicted\": round(y_pred, 4),\n",
    "                \"Abs Error\": round(abs_error, 4),\n",
    "                \"Rel Error (%)\": round(rel_error, 2)\n",
    "            })\n",
    "\n",
    "        r2 = r2_score(y_true_cv, y_pred_cv)\n",
    "        rmse = mean_squared_error(y_true_cv, y_pred_cv, squared=False)\n",
    "        mae = mean_absolute_error(y_true_cv, y_pred_cv)\n",
    "\n",
    "        print(f\"  n_components={n} | RMSECV={rmse:.4f}, RÂ²={r2:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "        metrics_summary.append({\n",
    "            \"n_components\": n,\n",
    "            \"RMSECV\": rmse,\n",
    "            \"R2\": r2,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "        details_by_n[n] = pd.DataFrame(detailed_records)\n",
    "\n",
    "    summary_df = pd.DataFrame(metrics_summary)\n",
    "\n",
    "    if fixed_n_components:\n",
    "        best_n = fixed_n_components\n",
    "    else:\n",
    "        best_n = summary_df.loc[summary_df[\"RMSECV\"].idxmin(), \"n_components\"]\n",
    "\n",
    "    best_details_df = details_by_n[best_n]\n",
    "\n",
    "    print(f\"\\nBest n_components: {best_n} with RMSECV = {summary_df.loc[summary_df['n_components'] == best_n, 'RMSECV'].values[0]:.4f}\")\n",
    "    print(f\"\\nâœ… The best number of components is: {best_n}\")\n",
    "\n",
    "    final_model = None\n",
    "    if return_model:\n",
    "        final_model = make_pipeline(StandardScaler(), PLSRegression(n_components=best_n))\n",
    "        final_model.fit(X, y)\n",
    "\n",
    "    if return_model:\n",
    "        return summary_df, best_n, best_details_df, final_model\n",
    "    else:\n",
    "        return summary_df, best_n, best_details_df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# AUTO-RUN FIRST\n",
    "# -------------------------------\n",
    "\n",
    "summary_df, best_n, details_df = perform_plsr_loocv_full_report(\n",
    "    element=\"Mn\",\n",
    "    emission_lines=[\"Mn 403.08 nm\", \"Mn 403.31 nm\"],\n",
    "    peak_max_df=peak_max_df,\n",
    "    element_concentrations=element_concentrations\n",
    ")\n",
    "\n",
    "print(\"\\nAuto-selected LOOCV summary:\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\nDetailed predictions for best n_components:\")\n",
    "import IPython.display as disp\n",
    "disp.display(details_df[[\"Left-Out Sample\", \"Training Samples\", \"True\", \"Predicted\", \"Abs Error\", \"Rel Error (%)\"]])\n",
    "\n",
    "# -------------------------------\n",
    "# OPTIONAL: MANUAL OVERRIDE\n",
    "# -------------------------------\n",
    "\n",
    "# To try your own n_components (e.g. 2), uncomment this:\n",
    "\n",
    "summary_df, best_n, details_df = perform_plsr_loocv_full_report(\n",
    "    element=\"Mn\",\n",
    "    emission_lines=[\"Mn 403.08 nm\", \"Mn 403.31 nm\"],\n",
    "    peak_max_df=peak_max_df,\n",
    "    element_concentrations=element_concentrations,\n",
    "    fixed_n_components=2\n",
    ")\n",
    "\n",
    "print(\"\\nManual override LOOCV summary:\")\n",
    "print(summary_df)\n",
    "print(\"\\nDetailed predictions for n_components=2:\")\n",
    "disp.display(details_df[[\"Left-Out Sample\", \"Training Samples\", \"True\", \"Predicted\", \"Abs Error\", \"Rel Error (%)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17044c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_plsr_loocv_full_report(\n",
    "    element,\n",
    "    emission_lines,\n",
    "    peak_max_df,\n",
    "    element_concentrations=None,\n",
    "    assign_sample_colors=None,\n",
    "    cap_width=0.006,\n",
    "    return_model=False\n",
    "):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.cross_decomposition import PLSRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "    if element_concentrations is None or element not in element_concentrations:\n",
    "        raise ValueError(f\"Missing concentration values for element '{element}'.\")\n",
    "\n",
    "    df = peak_max_df[element]\n",
    "    X = df[emission_lines].values\n",
    "    y = np.array(element_concentrations[element], dtype=float)\n",
    "    sample_labels = df.index.tolist()\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    max_n = min(n_samples - 1, n_features)\n",
    "\n",
    "    metrics_summary = []\n",
    "    details_by_n = {}\n",
    "\n",
    "    print(f\"LOOCV performance for element '{element}' with {max_n} max components:\")\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        y_true_cv = []\n",
    "        y_pred_cv = []\n",
    "        detailed_records = []\n",
    "\n",
    "        loo = LeaveOneOut()\n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            test_sample = sample_labels[test_idx[0]]\n",
    "            train_samples = [sample_labels[i] for i in train_idx]\n",
    "\n",
    "            model = make_pipeline(StandardScaler(), PLSRegression(n_components=n))\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)[0, 0]\n",
    "            y_true = y_test[0]\n",
    "\n",
    "            y_true_cv.append(y_true)\n",
    "            y_pred_cv.append(y_pred)\n",
    "\n",
    "            abs_error = abs(y_true - y_pred)\n",
    "            rel_error = abs_error / y_true * 100 if y_true != 0 else np.nan\n",
    "\n",
    "            detailed_records.append({\n",
    "                \"Left-Out Sample\": test_sample,\n",
    "                \"Training Samples\": train_samples,\n",
    "                \"True\": round(y_true, 4),\n",
    "                \"Predicted\": round(y_pred, 4),\n",
    "                \"Abs Error\": round(abs_error, 4),\n",
    "                \"Rel Error (%)\": round(rel_error, 2)\n",
    "            })\n",
    "\n",
    "        r2 = r2_score(y_true_cv, y_pred_cv)\n",
    "        rmse = mean_squared_error(y_true_cv, y_pred_cv, squared=False)\n",
    "        mae = mean_absolute_error(y_true_cv, y_pred_cv)\n",
    "\n",
    "        print(f\"  n_components={n} | RMSECV={rmse:.4f}, RÂ²={r2:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "        metrics_summary.append({\n",
    "            \"n_components\": n,\n",
    "            \"RMSECV\": rmse,\n",
    "            \"R2\": r2,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "        details_by_n[n] = pd.DataFrame(detailed_records)\n",
    "\n",
    "    summary_df = pd.DataFrame(metrics_summary)\n",
    "    best_n = summary_df.loc[summary_df[\"RMSECV\"].idxmin(), \"n_components\"]\n",
    "    best_details_df = details_by_n[best_n]\n",
    "\n",
    "    print(f\"\\nBest n_components: {best_n} with RMSECV = {summary_df.loc[summary_df['n_components'] == best_n, 'RMSECV'].values[0]:.4f}\")\n",
    "    print(f\"\\nâœ… The best number of components is: {best_n}\")  # <--- Added line\n",
    "\n",
    "    # Optionally return model trained on full data with best_n\n",
    "    final_model = None\n",
    "    if return_model:\n",
    "        final_model = make_pipeline(StandardScaler(), PLSRegression(n_components=best_n))\n",
    "        final_model.fit(X, y)\n",
    "\n",
    "    if return_model:\n",
    "        return summary_df, best_n, best_details_df, final_model\n",
    "    else:\n",
    "        return summary_df, best_n, best_details_df\n",
    "\n",
    "summary_df, best_n, details_df = perform_plsr_loocv_full_report(\n",
    "    element=\"Zn\",\n",
    "    emission_lines=[\"Zn 468.01 nm\", \"Zn 472.22 nm\", \"Zn 481.05 nm\"],\n",
    "    peak_max_df=peak_max_df,\n",
    "    element_concentrations=element_concentrations\n",
    ")\n",
    "\n",
    "summary_df\n",
    "details_df[[\"Left-Out Sample\", \"Training Samples\", \"True\", \"Predicted\", \"Abs Error\", \"Rel Error (%)\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
