{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fa3e29",
   "metadata": {},
   "source": [
    "# ** Predicting Elemental Concentrations in Scrap Alloys Using PLSR and Spectral Data **\n",
    "\n",
    "This script processes spectral data files, extracts peak intensities of specific elemental emission lines, and uses Partial Least Squares Regression (PLSR) to predict elemental concentrations in unknown test samples.\n",
    "\n",
    "âš›How it works\n",
    "1. Data Loading and Processing\n",
    "Recursively loads .txt spectral files from specified training and test directories.\n",
    "\n",
    "- Each file contains wavelength and intensity data.\n",
    "\n",
    "- Applies baseline correction and Standard Normal Variate (SNV) normalization to reduce noise and standardize spectra.\n",
    "\n",
    "- Averages multiple measurements per sample to obtain a representative spectrum.\n",
    "\n",
    "- Extracts peak intensity values near predefined emission wavelengths for elements: Mn, Si, Mg, Cu, and Zn.\n",
    "\n",
    "2. Training Data Preparation\n",
    "- Matches processed spectral peaks with known reference elemental concentrations for training samples.\n",
    "\n",
    "3. PLSR Model Training and Evaluation\n",
    "- For each element, selects relevant emission line features present in both training and test sets.\n",
    "\n",
    "- Fits a PLS regression model on the training set.\n",
    "\n",
    "- Evaluates model fit on training data using RÂ² and RMSE metrics.\n",
    "\n",
    "4. Prediction on Test Data\n",
    "- Uses trained models to predict elemental concentrations for test samples.\n",
    "\n",
    "5. Visualization and Output\n",
    "- Displays predicted concentrations in a table with sample IDs.\n",
    "\n",
    "- Generates grouped bar charts comparing predicted elemental concentrations across test samples.\n",
    "\n",
    "- Plots histograms to visualize the distribution of predicted concentrations per element.\n",
    "\n",
    "- Creates heatmaps for a compact overview of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import natsort\n",
    "\n",
    "# --- Configuration ---\n",
    "TRAIN_DIR = \"C:/Users/KA/OneDrive/Desktop/BAMAN/28.01.2025 BAM-Alu\"ðŸ‘ˆ#Certified reference materials \n",
    "TEST_DIR = \"C:/Users/KA/OneDrive/Desktop/T8/\"ðŸ‘ˆ#Scrap alloys with unknown concentrations\n",
    "\n",
    "peak_lines = {\n",
    "    \"Mn\": [403.08, 403.31],\n",
    "    \"Si\": [251.61, 288.16],\n",
    "    \"Mg\": [285.21, 383.23, 383.83, 518.36],\n",
    "    \"Cu\": [324.75, 327.40],\n",
    "    \"Zn\": [334.50, 468.01, 481.05]\n",
    "}\n",
    "\n",
    "reference_concentrations = {\n",
    "    'BAM-308':     {'Mn': 0.0342, 'Si': 0.0707, 'Mg': 2.2900, 'Cu': 1.3150, 'Zn': 5.6700}, \n",
    "    'BAM-311':     {'Mn': 0.694,  'Si': 0.204,  'Mg': 1.567,  'Cu': 4.653, 'Zn': 0.2005},\n",
    "    'BAM-M308a':   {'Mn': 0.0343, 'Si': 0.072,  'Mg': 2.280,  'Cu': 1.360, 'Zn': 5.61},\n",
    "    'BAM-M318':    {'Mn': 0.0985, 'Si': 1.211,  'Mg': 0.356,  'Cu': 0.0908, 'Zn': 0.0486},\n",
    "    'ERM-EB313':   {'Mn': 0.4950, 'Si': 0.363,  'Mg': 3.400,  'Cu': 0.0931, 'Zn': 0.1580},\n",
    "    'ERM-EB314a':  {'Mn': 0.404,  'Si': 11.51,  'Mg': 0.196,  'Cu': 2.080, 'Zn': 1.1},\n",
    "    'ERM-EB315a':  {'Mn': 0.311,  'Si': 9.88,   'Mg': 0.446,  'Cu': 2.460, 'Zn': 0.801},\n",
    "    'ERM-EB317':   {'Mn': 0.0912, 'Si': 0.0271, 'Mg': 2.390,  'Cu': 1.770, 'Zn': 6.93}\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_raw_data(directory):\n",
    "    data = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                sample = os.path.basename(os.path.dirname(os.path.join(root, file)))\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(root, file), delimiter=';', names=['wavelength', 'intensity'])\n",
    "                    df['wavelength'] = pd.to_numeric(df['wavelength'], errors='coerce')\n",
    "                    df.dropna(subset=['wavelength'], inplace=True)\n",
    "                    data.setdefault(sample, []).append(df)\n",
    "                except:\n",
    "                    continue\n",
    "    return data\n",
    "\n",
    "def baseline_correction(df):\n",
    "    from pybaselines import whittaker as pl\n",
    "    for col in [c for c in df.columns if c != 'wavelength']:\n",
    "        baseline, _ = pl.asls(df[col].values)\n",
    "        df[col] = (df[col] - baseline).clip(lower=0)\n",
    "    return df\n",
    "\n",
    "def snv(df):\n",
    "    for col in [c for c in df.columns if c != 'wavelength']:\n",
    "        spectrum = df[col]\n",
    "        mean = spectrum.mean()\n",
    "        std = spectrum.std()\n",
    "        df[col] = (spectrum - mean) / std if std != 0 else 0\n",
    "    return df\n",
    "\n",
    "def average_measurements(dfs):\n",
    "    combined = pd.concat(dfs, axis=1)\n",
    "    combined = combined.loc[:, ~combined.columns.duplicated()]\n",
    "    averaged = combined.drop(columns='wavelength', errors='ignore').mean(axis=1)\n",
    "    averaged_df = pd.DataFrame({'wavelength': dfs[0]['wavelength'], 'intensity': averaged})\n",
    "    return averaged_df\n",
    "\n",
    "def extract_peak_areas(df):\n",
    "    peaks = {}\n",
    "    for element, wls in peak_lines.items():\n",
    "        for wl in wls:\n",
    "            region = df[(df['wavelength'] >= wl - 0.1) & (df['wavelength'] <= wl + 0.1)]\n",
    "            peak_value = region['intensity'].max() if not region.empty else np.nan\n",
    "            peaks[f\"{element}_{wl:.2f}\"] = peak_value\n",
    "    return peaks\n",
    "\n",
    "def process_samples(path):\n",
    "    raw_data = load_raw_data(path)\n",
    "    peak_data = {}\n",
    "    for sample, dfs in raw_data.items():\n",
    "        processed = [snv(baseline_correction(df.copy())) for df in dfs]\n",
    "        avg = average_measurements(processed)\n",
    "        peaks = extract_peak_areas(avg)\n",
    "        peak_data[sample] = peaks\n",
    "    df = pd.DataFrame.from_dict(peak_data, orient='index')\n",
    "    df.index.name = 'Sample'\n",
    "    return df.sort_index(key=natsort.natsort_keygen())\n",
    "\n",
    "# --- Process training and test sets ---\n",
    "steel_df = process_samples(TRAIN_DIR)\n",
    "test_df = process_samples(TEST_DIR)\n",
    "y_train_df = pd.DataFrame.from_dict(reference_concentrations, orient='index')\n",
    "steel_df = steel_df.loc[y_train_df.index]\n",
    "\n",
    "# --- Model Training and Prediction ---\n",
    "predictions_clipped = {}\n",
    "predictions_raw = {}\n",
    "\n",
    "for element in y_train_df.columns:\n",
    "    feature_cols = [col for col in steel_df.columns if col.startswith(f\"{element}_\") and col in test_df.columns]\n",
    "    if not feature_cols:\n",
    "        print(f\"Skipping {element}: no matching peaks in test data.\")\n",
    "        continue\n",
    "\n",
    "    X_train = steel_df[feature_cols]\n",
    "    y_train = y_train_df[element]\n",
    "    X_test = test_df[feature_cols]\n",
    "\n",
    "    model = make_pipeline(StandardScaler(), PLSRegression(n_components=min(3, len(feature_cols))))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on training set (raw only)\n",
    "    y_train_pred = model.predict(X_train).flatten()\n",
    "    r2 = r2_score(y_train, y_train_pred)\n",
    "    rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "    print(f\"\\nElement: {element}\")\n",
    "    print(f\"  RÂ² (Train): {r2:.3f}\")\n",
    "    print(f\"  RMSE (Train): {rmse:.4f}\")\n",
    "\n",
    "    # Predict test set\n",
    "    y_pred_raw = model.predict(X_test).flatten()\n",
    "    y_pred_clipped = np.clip(y_pred_raw, 0, None)\n",
    "\n",
    "    predictions_raw[element] = y_pred_raw\n",
    "    predictions_clipped[element] = y_pred_clipped\n",
    "\n",
    "# --- Final Prediction Table ---\n",
    "y_pred_df = pd.DataFrame(predictions_clipped, index=test_df.index)\n",
    "y_pred_df.index = [f\"T8_S{i+1}\" for i in range(len(y_pred_df))]\n",
    "\n",
    "print(\"\\nPredicted concentrations for T8 test samples (clipped):\")\n",
    "print(y_pred_df.round(4).to_string())\n",
    "\n",
    "# --- Grouped Bar Chart ---\n",
    "ax = y_pred_df.plot(kind='bar', figsize=(7, 4), colormap='tab10')\n",
    "plt.ylabel(\"Predicted Concentration (%)\")\n",
    "plt.title(\"Predicted Elemental Concentrations for T8 Unknown Material\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Histograms ---\n",
    "for col in y_pred_df.columns:\n",
    "    plt.figure()\n",
    "    sns.histplot(y_pred_df[col], kde=True)\n",
    "    plt.title(f\"Distribution of Predicted {col} Concentration\")\n",
    "    plt.xlabel(f\"{col} Concentration (%)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "# --- Heatmap ---\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(y_pred_df, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Predicted Concentration (%)'})\n",
    "plt.title(\"Predicted Elemental Concentrations for T8 Unknown Material\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
